"""

    To run this script the following are needed:
    1. export accession id of submission e.g. 
        export ACCNO="S-BIAD679"
    2. env variables for convert_to_zarr e.g.
        export bioformats2raw_java_home=/miniconda3/envs/bia/
        export bioformats2raw_bin=/miniconda3/envs/bia/bin/bioformats2raw
    3. AWS S3 credentials for upload to Embassy s3 e.g.
        export AWS_PROFILE=embassy 
        export AWS_SHARED_CREDENTIALS_FILE=/.aws/embassy_s3_credentials
        export AWS_CONFIG_FILE=/.aws/embassy_s3_config
       OR
        export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXXXXXXXXX
        export AWS_SECRET_ACCESS_KEY=abcdefgh1234567890

    The following are required if using Singularity container e.g.
    1. export SINGULARITY_CONTAINER_PATH="/singularity/bia_v1.2.1.sif"
    2. export CONTAINER_COMMAND_PREFIX="conda run -n bia"

    The following are optional depending on your setup:
    1. Overrides for default storage (esp. if running on EBI clusters) e.g.
        export data_dirpath=/hps/nobackup/.bia-integrator-data/
        export cache_root_dirpath=/hps/nobackup/.cache/bia-converter

    2. Override default location of bia-integrator scripts:
        export BIA_INTEGRATOR_TOOLS_SCRIPT_DIR="/bia-integrator/tools/scripts/"
    3. Override default (6) number of images to convert:
        export BIA_INTEGRATOR_N_IMAGES_TO_CONVERT=3

    To run workflow
    1. Activate virtual environment containing snakemake tools:
        source ${BIA_INTEGRATOR_TOOLS_SCRIPT_DIR}../venv/bin/activate
    2. Run command from of bia-integrator/tools/snakemake:
        snakemake --cores 6 work_dir/${ACCNO}/final_output_${ACCNO}.log

"""


from pathlib import Path
import re
import subprocess
import os

# Set directory for artefacts
work_dir = "work_dir/" + os.environ["ACCNO"]

# Get number of images to convert to zarr format
n_images_to_convert = os.environ.get("BIA_INTEGRATOR_N_IMAGES_TO_CONVERT", "6")

# Prefix to append when running in singularity container
command_prefix = os.environ.get("CONTAINER_COMMAND_PREFIX", "")

# Set directory for scripts when using singularity or a custom setup
script_dir = os.environ.get("BIA_INTEGRATOR_TOOLS_SCRIPT_DIR", "../scripts")

singularity_container_path = os.environ.get("SINGULARITY_CONTAINER_PATH", "")

rule all:
    input:
        work_dir + "/final_output_{accno}.log"
    
rule ingest_from_biostudies:
    output:
        work_dir + "/ingest_from_biostudies.log"
    singularity:
        singularity_container_path
    shell:
        r"""
            if [[ $ACCNO =~ "EMPIAR" ]]
            then
                touch {output}
            else
                {command_prefix} python {script_dir}/ingest_from_biostudies.py $ACCNO > {output}
            fi
        """

rule index_zips_in_study:
    input:
        work_dir + "/ingest_from_biostudies.log"
    output:
        work_dir + "/index_zips_in_study.log"
    singularity:
        singularity_container_path
    shell:
        r"""
            for ZIP_FILEREF_ID in `biaint filerefs list $ACCNO | grep -P '\.zip|\bdirectory\b' | grep -v '\.zarr' | grep -v 'file_in_zip' | cut -d',' -f1`; do python {script_dir}/index_zip_in_study.py $ACCNO $ZIP_FILEREF_ID 2>&1 | tee -a {output}; done
            touch {output}
        """

rule summarise_study_filetypes:
    input:
        work_dir + "/index_zips_in_study.log"
    output:
        work_dir + "/summarise_study_filetypes.log"
    shell:
        "{command_prefix} python {script_dir}/summarise_study_filetypes.py $ACCNO 2>&1 | tee {output}"

# Create image representations for filerefs that can be converted to zarrs
# in a straightforward manner by bioformats2raw 'easily convertable', then
# for (zipped) zarr files
rule auto_create_image_representations:
    input:
        work_dir + "/summarise_study_filetypes.log"
    output:
        work_dir + "/image_representations.log"
    singularity:
        singularity_container_path
    shell:
        """
            {command_prefix} python {script_dir}/assign_all_easily_convertible_images_from_filerefs.py $ACCNO 2>&1 | tee {output} && \
            {command_prefix} python {script_dir}/assign_zipped_zarr_from_filerefs.py $ACCNO 2>&1 | tee -a {output}
        """

# Set source image for file references which are AI annotations and has a source image.
# This is the way to set which files are annotations in a dataset. 
# The script only works for a limited number of accessions; you need to modify the script 
# for other accessions.
rule auto_create_source_image_attributes:
    input:
        work_dir + "/image_representations.log"
    output:
        work_dir + "/source_image_attributes.log"
    singularity:
        singularity_container_path
    shell:
        "{command_prefix} python {script_dir}/assign_source_image_for_annotations.py $ACCNO 2>&1 | tee {output}"

rule auto_create_image_aliases:
    input:
        work_dir + "/source_image_attributes.log"
    output:
        work_dir + "/image_aliases.log"
    singularity:
        singularity_container_path
    shell:
        "{command_prefix} python {script_dir}/assign_alias_images.py $ACCNO 2>&1 | tee {output}"

# Creates aliases for AI annotation files (i.e. aliases for segmentation files)  
rule auto_create_annotation_aliases:
    input:
        work_dir + "/image_aliases.log"
    output:
        work_dir + "/annotation_aliases.log"
    singularity:
        singularity_container_path
    shell:
        "{command_prefix} python {script_dir}/assign_alias_to_annotations.py $ACCNO 2>&1 | tee {output}"

rule generate_image_size_annotations:
    input:
        work_dir + "/annotation_aliases.log"
    output:
        work_dir + "/generate_image_size_annotations.log"
    singularity:
        singularity_container_path
    shell:
        "{command_prefix} python {script_dir}/generate_image_download_size_annotations.py $ACCNO 2>&1 | tee {output}"

# Get image_representations dynamically
# By default only first 6. Use BIA_INTEGRATOR_N_IMAGES_TO_CONVERT 
# environment variable if you want any other number or all of them
checkpoint get_image_reps_to_convert:
    input: work_dir + "/generate_image_size_annotations.log"
    output:
        im_rep_dir = directory(work_dir + "/im_reps")
    singularity:
        singularity_container_path
    shell:
        """
            # For some reason (probably as things move through the pipes?),
            # this command causes snakemake to exit (as though bash 
            # returned an error) when it has run OK. Therefore disable 
            # exit on error just for this.
            set +e
                grep "json" {input} | head -n {n_images_to_convert} > {input}.temp
            set -e

            OUTPUT_DIR='{output.im_rep_dir}'
            REGEX="([0-9|a-z]+-[0-9|a-z]+-[0-9|a-z]+-[0-9|a-z]+-[0-9|a-z]+)"
            mkdir $OUTPUT_DIR
            while read line; do if [[ $line =~ $REGEX ]]; then touch "$OUTPUT_DIR/${{BASH_REMATCH[1]}}"; fi; done < {input}.temp
        """

# This step of the pipeline runs N (default 6) independent jobs. Some
# of these may fail. The pipeline will continue regardless of failure
# as long as at least one independent job completed successfully
rule convert_to_zarr_and_upload:
    input:
        im_ref = work_dir + "/im_reps/{i,[a-z|\d|-]+}"
    output:
        im_ref = work_dir + "/im_reps_output/{i}"
    singularity:
        singularity_container_path
    shell:
        """
            # Manipulate exit status to allow continuation in event of error
            # See https://snakemake.readthedocs.io/en/stable/project_info/faq.html#my-shell-command-fails-with-exit-code-0-from-within-a-pipe-what-s-wrong
            set +e
            IM_REF=$(basename {input.im_ref})
            # If zipped_zarr use remote_zipped_zarr_to_s3
            biaint images show $ACCNO $IM_REF | grep zipped_zarr
            exitcode=$?
            if [ $exitcode -eq 0 ]
            then
                {command_prefix} python {script_dir}/remote_zipped_zarr_to_s3.py $ACCNO $IM_REF > {output.im_ref}
            else
                # Otherwise convert and upload
                {command_prefix} python {script_dir}/convert_to_zarr_and_upload.py $ACCNO $IM_REF > {output.im_ref}
            fi

            exitcode=$?
            if [ $exitcode -eq 0 ]
            then
                touch {output.im_ref}.success
            fi
            touch {output.im_ref}
            exit 0
        """
# The command for this rule could be placed in convert_to_zarr_and_upload
# but putting it here to make the steps involved clearer
rule generate_thumbnails:
    input:
        work_dir + "/im_reps_output/{i,[a-z|\d|-]+[^\.success]}"
    output:
        work_dir + "/gen_thumb_output/{i}"
    singularity:
        singularity_container_path
    shell:
        """
            # Allow continuation in event of error - see comments in
            # rule 'convet_to_zarr_and_upload' above
            set +e
            if [ -f {input}.success ]
            then
                IM_REF=$(basename {input})
                {command_prefix} python {script_dir}/generate_thumbnail.py $ACCNO $IM_REF > {output}

                exitcode=$?
                if [ $exitcode -eq 0 ]
                then
                    touch {output}.success
                fi
            fi
            touch {output}
            exit 0
        """
def aggregate_converted_im_reps(wildcards):
    """Return converted image_representations"""
    checkpoint_output = checkpoints.get_image_reps_to_convert.get(**wildcards).output[0]
    im_reps_paths = expand(work_dir + "/gen_thumb_output/{i}", i=glob_wildcards(os.path.join(checkpoint_output, '{i,[a-z|\d|-]+}')).i)
    return [i for i in filter(lambda p: not p.endswith("success"), im_reps_paths)]

rule generate_representative_image:
    # Although the aggregate function returns a space separated list
    # of paths for the converted image representations,
    # We loop through the returned paths checking for the first one
    # that was successfully converted. We then use 'basename' in the
    # shell to get the reference of the image representation.
    input:
        aggregate_converted_im_reps
    output:
        work_dir + "/representative_image.log"
    singularity:
        singularity_container_path
    shell:
        """
            for IM_REF in {input}
            do
                if [ -f ${{IM_REF}}.success ]
                then
                    IMAGE_ID=$(basename $IM_REF)
                    {command_prefix} python {script_dir}/generate_representatives_for_annotation_and_image_and_set_to_default.py $ACCNO $IMAGE_ID > {output}
                    exit 0
                fi
            done
            
            # Code reaches here if no succesfully converted images
            # therefore, cause bash error (or have generic image?)
            echo "ERROR: No successfully converted images in IM_REFS supplied - exiting"
            exit 1
        """

rule fetch_ome_metadata_for_all_images_in_study:
    input:
        work_dir + "/representative_image.log"
    output:
        work_dir + "/fetch_ome_metadata_for_all_images_in_study.log"
    singularity:
        singularity_container_path
    shell:
        """
            {command_prefix} python {script_dir}/fetch_ome_metadata_for_all_images_in_study.py $ACCNO > {output}
        """

rule annotate_study_from_zarr:
    input:
        work_dir + "/fetch_ome_metadata_for_all_images_in_study.log"
    output:
        work_dir + "/annotate_study_from_zarr.log"
    singularity:
        singularity_container_path
    shell:
        """
            {command_prefix} python {script_dir}/annotate_study_from_zarr.py $ACCNO > {output}
        """

rule run_post_conversion_annotation:
    input:
        work_dir + "/annotate_study_from_zarr.log"
    output:
        work_dir + "/post_conversion_annotation.log"
    singularity:
        singularity_container_path
    shell:
        """
            {command_prefix} python {script_dir}/run_post_conversion_annotation.py $ACCNO > {output}
        """

# Collect the output logs so we have one file for 'all' rule
rule combine_output:
    output:
        combined = work_dir + "/final_output_{accno}.log"
    input:
        work_dir + "/post_conversion_annotation.log"
    shell:
        "echo {input} > {output.combined}"
